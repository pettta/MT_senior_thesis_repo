{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6042148-53a9-44e9-8fef-64119cc4531d",
   "metadata": {},
   "source": [
    "# Reassemble Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8511a5ad-0794-4c08-a9b3-7ebda43176fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def reassemble_test_dataset(json_path, engl_paths, japn_paths):\n",
    "    \"\"\"\n",
    "    Reassembles the dataset from the original files using indices stored in a JSON file.\n",
    "\n",
    "    Args:\n",
    "    json_path (str): Path to the JSON file containing the indices.\n",
    "    engl_paths (list): List of paths to the English files in the order they were originally concatenated.\n",
    "    japn_paths (list): List of paths to the Japanese files in the order they were originally concatenated.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The reassembled DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the indices from the JSON file\n",
    "    with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "        indices = json.load(json_file)\n",
    "    \n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Extract and concatenate the subsets using the indices\n",
    "    for engl_path, japn_path, index_key in zip(engl_paths, japn_paths, indices):\n",
    "        with open(engl_path, 'r', encoding='utf-8') as engl_file, open(japn_path, 'r', encoding='utf-8') as japn_file:\n",
    "            engl_lines = engl_file.readlines()\n",
    "            japn_lines = japn_file.readlines()\n",
    "        \n",
    "        # Extract the subset of lines using the index\n",
    "        start_index = indices[index_key]\n",
    "        engl_subset = engl_lines[start_index:start_index + 300]\n",
    "        japn_subset = japn_lines[start_index:start_index + 300]\n",
    "\n",
    "        # Create a new DataFrame with the extracted lines\n",
    "        new_data = {'English': engl_subset, 'Japanese': japn_subset}\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "\n",
    "        # Concatenate the new DataFrame with the existing one\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "json_path = './model_outputs/test/en_to_jp/index.json'\n",
    "engl_paths = [\n",
    "    './datasets/public/kftt-data-1.0/data/tok/kyoto-test.en',\n",
    "    './datasets/public/pheMT_final/tok.en',\n",
    "    './datasets/private/ASPEC/ASPEC-JE/devtest/devtest.tok.en'\n",
    "]\n",
    "japn_paths = [\n",
    "    './datasets/public/kftt-data-1.0/data/tok/kyoto-test.ja',\n",
    "    './datasets/public/pheMT_final/tok.ja',\n",
    "    './datasets/private/ASPEC/ASPEC-JE/devtest/devtest.tok.ja'\n",
    "]\n",
    "kftt_phemt_aspec = reassemble_test_dataset(json_path, engl_paths, japn_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4b3b9-bfc2-4da0-8846-6cf7b488ecb4",
   "metadata": {},
   "source": [
    "# M4T Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4f7fa4-a507-43c7-baa8-b5a89ef0c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/thomaspett/Desktop/projects/MT_senior_thesis_repo/env\n",
      "\n",
      "  added / updated specs:\n",
      "    - libsndfile==1.0.31\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  gettext            conda-forge/osx-arm64::gettext-0.22.5-h8fbad5d_2 \n",
      "  gettext-tools      conda-forge/osx-arm64::gettext-tools-0.22.5-h8fbad5d_2 \n",
      "  libasprintf        conda-forge/osx-arm64::libasprintf-0.22.5-h8fbad5d_2 \n",
      "  libasprintf-devel  conda-forge/osx-arm64::libasprintf-devel-0.22.5-h8fbad5d_2 \n",
      "  libflac            conda-forge/osx-arm64::libflac-1.3.4-h07bb92c_0 \n",
      "  libgettextpo       conda-forge/osx-arm64::libgettextpo-0.22.5-h8fbad5d_2 \n",
      "  libgettextpo-devel conda-forge/osx-arm64::libgettextpo-devel-0.22.5-h8fbad5d_2 \n",
      "  libiconv           conda-forge/osx-arm64::libiconv-1.17-h0d3ecfb_2 \n",
      "  libintl            conda-forge/osx-arm64::libintl-0.22.5-h8fbad5d_2 \n",
      "  libintl-devel      conda-forge/osx-arm64::libintl-devel-0.22.5-h8fbad5d_2 \n",
      "  libogg             conda-forge/osx-arm64::libogg-1.3.4-h27ca646_1 \n",
      "  libopus            conda-forge/osx-arm64::libopus-1.3.1-h27ca646_1 \n",
      "  libsndfile         conda-forge/osx-arm64::libsndfile-1.0.31-h9f76cd9_1 \n",
      "  libvorbis          conda-forge/osx-arm64::libvorbis-1.3.7-h9f76cd9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge libsndfile==1.0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef5b1162-575a-4c78-897b-1922da356620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n",
      "/Users/thomaspett/Desktop/projects/MT_senior_thesis_repo/env/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from seamless_communication.inference import Translator\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#translator = Translator(\"seamlessM4T_large\", \"vocoder_v2\", torch.device(\"mps:0\"), torch.float16)\n",
    "m4tv1_translator = Translator(\n",
    "\"seamlessM4T_large\",\n",
    "\"vocoder_v2\",\n",
    "device=torch.device(\"mps:0\"),\n",
    "dtype=torch.float16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "454de7c7-032b-43c9-88a5-b4938062ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def m4t_v1_translate_and_save(df, translator, src_lang, tgt_lang, output_file):\n",
    "    # src_lang, tgt_lang = 'eng' or 'jpn'\n",
    "    try:\n",
    "        # Open the output file in write mode\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            # Iterate over each row in the DataFrame\n",
    "            for _, row in df.iterrows():\n",
    "                index_row = 'Japanese' if src_lang == 'jpn' else 'English'\n",
    "                source_text = row[index_row]\n",
    "\n",
    "                # Translate the text using the local translator\n",
    "                translated_text, _ = translator.predict(\n",
    "                    input=source_text,\n",
    "                    task_str=\"T2TT\",\n",
    "                    tgt_lang=tgt_lang,\n",
    "                    src_lang=src_lang,\n",
    "                    unit_generation_opts=None, \n",
    "                )\n",
    "                \n",
    "                # Write the translated text to the output file\n",
    "                file.write(str(translated_text[0]) + '\\n')\n",
    "                # print(\"SRC TEXT:\", source_text, \"\\n\", \"OUTPUT TEXT:\", str(translated_text[0]), \"\\n\") # TODO remove \n",
    "                # break # TODO REMOVE \n",
    "\n",
    "        print(f\"Translation completed. Translations saved to: {output_file}\")\n",
    "\n",
    "    except IOError:\n",
    "        print(f\"Error writing to file: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during translation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b380-8c4e-4ff1-9be1-b479898738a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO eng->jap \n",
    "m4t_v1_translate_and_save(df=kftt_phemt_aspec, translator=m4tv1_translator, src_lang='eng', tgt_lang='jpn', output_file='model_outputs/test/en_to_jp/m4tv1/out.txt')\n",
    "# TODO jap->eng \n",
    "m4t_v1_translate_and_save(df=kftt_phemt_aspec, translator=m4tv1_translator, src_lang='jpn', tgt_lang='eng', output_file='model_outputs/test/jp_to_en/m4tv1/out.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
